{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time, logging\n",
    "import gensim\n",
    "from gensim.models import Phrases, KeyedVectors\n",
    "from string import punctuation\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1136880\r\n",
      "drwxr-xr-x  11 rsilvei  ADESI\\Domain Users   352B Aug 19 23:08 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   6 rsilvei  ADESI\\Domain Users   192B Aug 14 10:51 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "drwxr-xr-x   2 rsilvei  ADESI\\Domain Users    64B Aug 14 22:25 \u001b[1m\u001b[36mjogo_gremio_athletico\u001b[m\u001b[m\r\n",
      "-rw-r--r--   1 rsilvei  ADESI\\Domain Users   100M Aug 14 22:18 tweets_1.txt\r\n",
      "-rw-r--r--   1 rsilvei  ADESI\\Domain Users    48M Aug 16 14:20 tweets_2_d47c92ce-501e-480a-afd9-f30343d8474f.txt\r\n",
      "-rw-r--r--   1 rsilvei  ADESI\\Domain Users    29M Aug 14 20:37 tweets_3.txt\r\n",
      "-rw-r--r--   1 rsilvei  ADESI\\Domain Users   104M Aug 15 09:40 tweets_4b05f867-a2ba-418d-926b-857288867813.txt\r\n",
      "-rw-r--r--   1 rsilvei  ADESI\\Domain Users    50M Aug 19 10:56 tweets_5b8da1aa-a089-4b42-9c49-64d2cde4dc52.txt\r\n",
      "-rw-r--r--   1 rsilvei  ADESI\\Domain Users    44M Aug 20 00:15 tweets_84db8ab8-4af8-4945-96ea-10662d9f74ae.txt\r\n",
      "-rw-r--r--   1 rsilvei  ADESI\\Domain Users   153M Aug 18 20:13 tweets_a3e3c5c4-7181-4168-bfbc-ccd13cf1aed2.txt\r\n",
      "-rw-r--r--@  1 rsilvei  ADESI\\Domain Users   1.6K Aug 15 10:06 twitter_streamer.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ../data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_files = [\n",
    "    'tweets_1.txt',\n",
    "    'tweets_2_d47c92ce-501e-480a-afd9-f30343d8474f.txt',\n",
    "    'tweets_3.txt',\n",
    "    'tweets_4b05f867-a2ba-418d-926b-857288867813.txt',\n",
    "    'tweets_5b8da1aa-a089-4b42-9c49-64d2cde4dc52.txt',\n",
    "    'tweets_84db8ab8-4af8-4945-96ea-10662d9f74ae.txt',\n",
    "    'tweets_a3e3c5c4-7181-4168-bfbc-ccd13cf1aed2.txt'  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweets_1.txt'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = []\n",
    "for file in tweet_files:\n",
    "    tweets_file = open(os.path.join('../data', file), \"r\")\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            tweets_data.append(tweet)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83055\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --------------------------------------------------\n",
      "Gr√™mio escalado de forma oficial para a Semifinal da Copa do Brasil https://t.co/IfEec4EYUK\n",
      "pt\n",
      "False\n",
      "1 --------------------------------------------------\n",
      "Me inscrevi em 3 editais de treinamento profissional pela uf, me inscrevi em duas vagas de est√°gio pela net.\n",
      "Confio‚Ä¶ https://t.co/kqZEy0tJQE\n",
      "pt\n",
      "True\n",
      "2 --------------------------------------------------\n",
      "Gr√™mio definido para a semifinal da Copa do Brasil\n",
      "pt\n",
      "False\n",
      "3 --------------------------------------------------\n",
      "RT @lets_mariano: se a 2¬∞ temporada n√£o sair logo eu vou levar a netflix pras ideia https://t.co/YboDVLVgUV\n",
      "pt\n",
      "False\n",
      "4 --------------------------------------------------\n",
      "RT @arctmankeys: ngm:\n",
      "\n",
      "estudante de medicina no primeiro semestre: https://t.co/RuFT970Otc\n",
      "pt\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(tweets_data[0:5]):\n",
    "    print(i, '-'*50)\n",
    "    print(item['text'])\n",
    "    print(item['lang'])\n",
    "    print(item['truncated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>truncated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, lang, hashtags, user, location, truncated]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.DataFrame(columns=['text','lang','hashtags','user','location','truncated'])\n",
    "tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] - TEXT - Gr√™mio escalado de forma oficial para a Semifinal da Copa do Brasil https://t.co/IfEec4EYUK\n",
      "[5000] - TEXT - RT @arctmankeys: ngm:\n",
      "\n",
      "estudante de medicina no primeiro semestre: https://t.co/RuFT970Otc\n",
      "[10000] - TEXT - RT @jfrmnt: Lista de comunistas atualizada:\n",
      "The NY Times\n",
      "The Economist\n",
      "Le Mond\n",
      "Alemanha \n",
      "ONU\n",
      "Madonna\n",
      "Veja\n",
      "Reinaldo Azevedo\n",
      "Papa Francisco\n",
      "G‚Ä¶\n",
      "[15000] - TEXT - @BADBYEMP3 to quase man algu√©m me segura pra n√£o mudar a senha da netflix\n",
      "[20000] - TEXT - RT @Pedro_Britto16: A caminhada √© o seguinte a segunda temporada tem que ter mais episodio certo fam√≠lia e a liberdade do irm√£o bad√° tem qu‚Ä¶\n",
      "[25000] - TEXT - RT @lancnetflix: \"Nerve\" e mais 35 filmes que retornar√£o √† Netflix: https://t.co/UKnBft3dpK https://t.co/1q3rndVWHo\n",
      "[30000] - TEXT - RT @lelispatricia: Brasil √© o √∫nico pa√≠s em que o  pobre, sem estudo ou emprego, defende os cortes na educa√ß√£o e n√£o consegue reconhecer o‚Ä¶\n",
      "[35000] - TEXT - Eu pedi e o @Gremio  atendeu!!! Agora a ta√ßa!!!!\n",
      "[40000] - TEXT - RT @becahmaciel: eu t√¥ rindo muito KKKKKKKKKKKKKKKKKK netflix eu te amo entenda https://t.co/SFLZazgqgU\n",
      "[45000] - TEXT - @Gremio A√ç √© TE AMO\n",
      "[50000] - TEXT - A jogada de Jo√£o F√©lix que est√° a dar que falar https://t.co/yaepYhzfVu\n",
      "[55000] - TEXT - RT @lnterDados: üëï Camisas do Inter 2019/20\n",
      "üí∞ 119,90\n",
      "üìå P, M, G, GG, GGG\n",
      "üí≥ Boleto ou cart√£o de cr√©dito em at√© 12x\n",
      "üîí Mercado Pago ou PayPal\n",
      "‚úàÔ∏è‚Ä¶\n",
      "[60000] - TEXT - RT @Gremio: üá™üá™ HOJE √â #DiaDeGr√™mio üí™\n",
      "üÜö @Palmeiras\n",
      "üèü Arena do Gr√™mio\n",
      "‚åö 21h30\n",
      "üèÜ #Libertadores2019\n",
      "#‚É£ #GRExPAL\n",
      "\n",
      "‚û° Ingressos: https://t.co/kSiL‚Ä¶\n",
      "[65000] - TEXT - @Haddad_Fernando @Marcelo_Mendonc Meritocracia igual a do mais novo diplomata. √â coisa pra filme se Netflix..\n",
      "[70000] - TEXT - RT @emilyrnobre: Hoje ta pedindo uma cia e Netflix\n",
      "[75000] - TEXT - RT @Jonas48140701: N√£o √© s√≥ uma quest√£o de vagas,tamb√©m √© uma quest√£o de agentes penitenci√°rios.\n",
      "Policiais e viaturas que poderiam fazer a‚Ä¶\n",
      "[80000] - TEXT - @JuarezRoth Acho que vai depender mais do enfrentamento da libertadores. Se o inter for eliminado pelo flamengo, o cruzeiro pode aproveitar. √â muito dif√≠cil time ga√∫cho perder em casa depois que ganhou fora.\n"
     ]
    }
   ],
   "source": [
    "for x,item in enumerate(tweets_data):\n",
    "    text = \"\"\n",
    "\n",
    "    try:\n",
    "        if item['truncated']:\n",
    "            text=item['extended_tweet']['full_text']\n",
    "        else:\n",
    "            text=item['text']\n",
    "        tweets.loc[x]=[text,item['lang'],item['entities'],item['user']['screen_name'],item['user']['location'],item['truncated']]\n",
    "        if x % 5000 == 0:\n",
    "            print(\"[{}] - TEXT - {}\".format(x,text))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83055"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets[tweets.lang == 'pt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@mahoubitch O maior erro do nerd foi existir, infelizmente'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_tweets = tweets[tweets.lang == 'pt'].reset_index(drop=True)\n",
    "pt_tweets.loc[19]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_user(text):\n",
    "    text = text.split()\n",
    "    users = []\n",
    "    for item in text:\n",
    "        try:\n",
    "            result = re.search('@(.*)', item)\n",
    "            name = result.group(1)\n",
    "            users.append(\"@\"+name)\n",
    "        except:\n",
    "            pass\n",
    "    text_filtered = [x for x in text if x not in users]\n",
    "    text_filtered = \" \".join(text_filtered)\n",
    "    return text_filtered, users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_latin_character(text):\n",
    "    text = unicodedata.normalize('NFKD',text).encode('ASCII','ignore').decode(\"utf-8\") # remove latin utf-8 characters\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_hashtag(text):\n",
    "    text = text.split()\n",
    "    hashtags = []\n",
    "    for item in text:\n",
    "        try:\n",
    "            result = re.search('#(.*)', item)\n",
    "            name = result.group(1)\n",
    "            hashtags.append(\"#\"+name)\n",
    "        except:\n",
    "            pass\n",
    "    text_filtered = [x for x in text if x not in hashtags]\n",
    "    text_filtered = \" \".join(text_filtered)\n",
    "    return text_filtered, hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_link(text):\n",
    "    text = text.split()\n",
    "    links = []\n",
    "    for item in text:\n",
    "        try:\n",
    "            result = re.search('http(.*)', item)\n",
    "            name = result.group(1)\n",
    "            links.append(item)\n",
    "        except:\n",
    "            pass\n",
    "    text_filtered = [x for x in text if x not in links]\n",
    "    text_filtered = \" \".join(text_filtered)\n",
    "    return text_filtered, links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Replace punctuation with tokens so we can use them in our model\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Remove user\n",
    "    text, _ = remove_user(text)\n",
    "    # Remove hashtag\n",
    "    text, _ = remove_hashtag(text)\n",
    "    # Remove links \n",
    "    text, _ = remove_link(text)\n",
    "    # Remove punctuation\n",
    "    text = strip_punctuation(text)\n",
    "    # Remove latin character\n",
    "    text = remove_latin_character(text)\n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    # Remove \"RT\" string\n",
    "    text = text.replace('rt', ' ')\n",
    "    #text = re.sub(r'[^\\w\\s]','',text) # strip punctuation\n",
    "    text = ' '.join(text.split()) ## replacing extra spaces\n",
    "    text = text.replace(\".\",\"\")\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_tweets['clean_text'] = pt_tweets['text'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o maior erro do nerd foi existir infelizmente'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_tweets.loc[19]['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - gremio escalado de forma oficial para a semifinal da copa do brasil\n",
      "1 - me inscrevi em 3 editais de treinamento profissional pela uf me inscrevi em duas vagas de estagio pela net confio que nao vou passar em nenhum\n",
      "2 - gremio definido para a semifinal da copa do brasil\n",
      "3 - se a 2 temporada nao sair logo eu vou levar a netflix pras ideia\n",
      "4 - ngm estudante de medicina no primeiro semestre\n",
      "5 - ja estamos em casa para a primeira pa ida da semifinal da\n",
      "6 - to queria um emprego p bancar minha manutencao na facul slc ir p sp todo dia me desanima mt daqui\n",
      "7 - ouvi essa frase no trampo hj tem gente que quer emprego mas nao quer trabalhar so verdades kdfkkffk\n",
      "8 - parabens gremio pela classificacao grenal na final\n",
      "9 - nossa mas eu vou fazer tanto isso\n",
      "10 - vou esperar a guitarra hehehe dalhe nosso gremio imo al\n",
      "11 - ja estamos em casa para a primeira pa ida da semifinal da\n",
      "12 - desisto de engenharia\n",
      "13 - caralho que foda acabei de ver algumas paradas do novo especial da netflix do whindersson e to feliz demais ta ligado quand\n",
      "14 - eu preciso tirar ca eira logo pra poder atropelar pessoas\n",
      "15 - fui tomar cafe e agora e no sofa a ver netflix esta bom mas estou sozinho uff e quase perfeito\n",
      "16 - dpritos e molho de queijo\n",
      "17 - isso o pig nao mostra\n",
      "18 - prefeitura tem 30 vagas para curso de assistencia logistica\n",
      "19 - o maior erro do nerd foi existir infelizmente\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print(i,\"-\", pt_tweets['clean_text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lang</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user</th>\n",
       "      <th>location</th>\n",
       "      <th>truncated</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83050</th>\n",
       "      <td>RT @futebol_pais: Na estreia de Z√© Ricardo, In...</td>\n",
       "      <td>pt</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>reidalliga12</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>na estreia de ze ricardo inter bateu o fo alez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83051</th>\n",
       "      <td>RT @thmwrvel: fa√ßo parte do 1% do p√∫blico da N...</td>\n",
       "      <td>pt</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>Ruan37175716</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>faco pa e do 1 do publico da netflix que nao t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83052</th>\n",
       "      <td>RT @madureberti: a menina rom√¢ntica q habita e...</td>\n",
       "      <td>pt</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>Barbosa9Marta</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>a menina romantica q habita em mim agradece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83053</th>\n",
       "      <td>Meu maxilar t√° at√© doendo de tanto rir do show...</td>\n",
       "      <td>pt</td>\n",
       "      <td>{'hashtags': [], 'urls': [], 'user_mentions': ...</td>\n",
       "      <td>whysosexydemi</td>\n",
       "      <td>journalism &amp; photography</td>\n",
       "      <td>False</td>\n",
       "      <td>meu maxilar ta ate doendo de tanto rir do show...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83054</th>\n",
       "      <td>RT @madureberti: a menina rom√¢ntica q habita e...</td>\n",
       "      <td>pt</td>\n",
       "      <td>{'hashtags': [], 'urls': [{'url': 'https://t.c...</td>\n",
       "      <td>a_furtado2</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>a menina romantica q habita em mim agradece</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text lang  \\\n",
       "83050  RT @futebol_pais: Na estreia de Z√© Ricardo, In...   pt   \n",
       "83051  RT @thmwrvel: fa√ßo parte do 1% do p√∫blico da N...   pt   \n",
       "83052  RT @madureberti: a menina rom√¢ntica q habita e...   pt   \n",
       "83053  Meu maxilar t√° at√© doendo de tanto rir do show...   pt   \n",
       "83054  RT @madureberti: a menina rom√¢ntica q habita e...   pt   \n",
       "\n",
       "                                                hashtags           user  \\\n",
       "83050  {'hashtags': [], 'urls': [], 'user_mentions': ...   reidalliga12   \n",
       "83051  {'hashtags': [], 'urls': [{'url': 'https://t.c...   Ruan37175716   \n",
       "83052  {'hashtags': [], 'urls': [{'url': 'https://t.c...  Barbosa9Marta   \n",
       "83053  {'hashtags': [], 'urls': [], 'user_mentions': ...  whysosexydemi   \n",
       "83054  {'hashtags': [], 'urls': [{'url': 'https://t.c...     a_furtado2   \n",
       "\n",
       "                       location truncated  \\\n",
       "83050                      None     False   \n",
       "83051                      None     False   \n",
       "83052                      None     False   \n",
       "83053  journalism & photography     False   \n",
       "83054                      None     False   \n",
       "\n",
       "                                              clean_text  \n",
       "83050  na estreia de ze ricardo inter bateu o fo alez...  \n",
       "83051  faco pa e do 1 do publico da netflix que nao t...  \n",
       "83052        a menina romantica q habita em mim agradece  \n",
       "83053  meu maxilar ta ate doendo de tanto rir do show...  \n",
       "83054        a menina romantica q habita em mim agradece  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_tweets.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sentences = list(pt_tweets['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for sent in raw_sentences:\n",
    "    sentences.append(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'menina', 'romantica', 'q', 'habita', 'em', 'mim', 'agradece']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phrases(sentences,min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_size = 50\n",
    "context_window = 8\n",
    "workers=4\n",
    "min_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(\n",
    "        sentences = sentences,\n",
    "        #sentences = bigram[sentences],\n",
    "        size = embedded_size, \n",
    "        window = context_window,\n",
    "        workers = workers,\n",
    "        min_count = min_count,\n",
    "        #sample = downsampling,\n",
    "        #hs = 1,\n",
    "        #negative = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inter', 0.8490924835205078),\n",
       " ('athletico', 0.8117737770080566),\n",
       " ('time', 0.8012363314628601),\n",
       " ('gremista', 0.7775830030441284),\n",
       " ('jogo', 0.7613232135772705),\n",
       " ('flamengo', 0.7354684472084045),\n",
       " ('atletico', 0.7266033887863159),\n",
       " ('rival', 0.706829309463501),\n",
       " ('tardelli', 0.7044202089309692),\n",
       " ('cruzeiro', 0.6981300115585327)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('gremio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gremio', 0.8490924835205078),\n",
       " ('athletico', 0.7781550884246826),\n",
       " ('jogo', 0.776072084903717),\n",
       " ('flamengo', 0.7659093141555786),\n",
       " ('cruzeiro', 0.7543831467628479),\n",
       " ('time', 0.7479128241539001),\n",
       " ('palmeiras', 0.7107430696487427),\n",
       " ('reposicao', 0.6960253715515137),\n",
       " ('atletico', 0.6947750449180603),\n",
       " ('mineirao', 0.6785922646522522)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ponta', 0.8588873147964478),\n",
       " ('pesquisas', 0.8373178243637085),\n",
       " ('deterioracao', 0.8326338529586792),\n",
       " ('investimento', 0.8305712938308716),\n",
       " ('pnd', 0.8268405199050903),\n",
       " ('servicos', 0.82682865858078),\n",
       " ('investimentos', 0.8263817429542542),\n",
       " ('eram', 0.8202065229415894),\n",
       " ('53', 0.8166924118995667),\n",
       " ('autentica', 0.8157235383987427)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('politica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sintonia', 0.6679555773735046),\n",
       " ('05x01', 0.6262835264205933),\n",
       " ('continuacao', 0.6036708354949951),\n",
       " ('terminei', 0.602993369102478),\n",
       " ('filme', 0.599368691444397),\n",
       " ('starz', 0.5984426140785217),\n",
       " ('seriados', 0.5753488540649414),\n",
       " ('saga', 0.5657902359962463),\n",
       " ('microondas', 0.5573458075523376),\n",
       " ('garotinha', 0.5448958873748779)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('netflix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsilvei/Envs/nlp_new/lib/python3.6/site-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('vetores.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 14240\r\n",
      "drwxr-xr-x  9 rsilvei  ADESI\\Domain Users   288B Aug 20 14:22 \u001b[1m\u001b[36m.\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  6 rsilvei  ADESI\\Domain Users   192B Aug 14 10:51 \u001b[1m\u001b[36m..\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  3 rsilvei  ADESI\\Domain Users    96B Aug 20 13:19 \u001b[1m\u001b[36m.ipynb_checkpoints\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 rsilvei  ADESI\\Domain Users    27K Aug 20 14:21 1.word2vec_trainer.ipynb\r\n",
      "drwxr-xr-x  6 rsilvei  ADESI\\Domain Users   192B Aug 20 13:18 \u001b[1m\u001b[36mdemo_1\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  3 rsilvei  ADESI\\Domain Users    96B Aug 14 18:31 \u001b[1m\u001b[36mdemo_2\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  3 rsilvei  ADESI\\Domain Users    96B Aug 14 18:30 \u001b[1m\u001b[36mdemo_3\u001b[m\u001b[m\r\n",
      "drwxr-xr-x  3 rsilvei  ADESI\\Domain Users    96B Aug 14 18:34 \u001b[1m\u001b[36mdemo_4\u001b[m\u001b[m\r\n",
      "-rw-r--r--  1 rsilvei  ADESI\\Domain Users   6.9M Aug 20 14:22 vetores.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2919', 0.6444302797317505),\n",
       " ('jogo', 0.6411250829696655),\n",
       " ('corretas', 0.6131941080093384),\n",
       " ('flamengo', 0.607387125492096),\n",
       " ('bank', 0.5846786499023438),\n",
       " ('grenal', 0.5808649659156799),\n",
       " ('time', 0.5799593329429626),\n",
       " ('santostemos', 0.5762511491775513),\n",
       " ('intergremio', 0.5759652256965637),\n",
       " ('aston', 0.5759439468383789)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['gremio', 'inter'], negative=['cebolinha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_new)",
   "language": "python",
   "name": "nlp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
