{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from pytorch_transformers import BertConfig, BertTokenizer, BertForQuestionAnswering\n",
    "from pytorch_transformers import XLNetConfig, XLNetForQuestionAnswering, XLNetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'bert': (BertConfig, BertForQuestionAnswering, BertTokenizer),\n",
    "    'xlnet': (XLNetConfig, XLNetForQuestionAnswering, XLNetTokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnswering(object):\n",
    "    def __init__(self, config_file, weight_file, tokenizer_file, model_type ):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.config_class, self.model_class, self.tokenizer_class = MODEL_CLASSES[model_type]\n",
    "        self.config = self.config_class.from_json_file(config_file)\n",
    "        self.model = self.model_class(self.config)\n",
    "        self.model.load_state_dict(torch.load(weight_file, map_location=self.device))\n",
    "        self.tokenizer = self.tokenizer_class(tokenizer_file)\n",
    "        self.model_type = model_type\n",
    "    \n",
    "    def to_list(self, tensor):\n",
    "        return tensor.detach().cpu().tolist()\n",
    "\n",
    "    def get_reply(self, question, passage):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            input_ids, _ , tokens = self.prepare_features(question, passage)\n",
    "            if self.model_type == 'bert':\n",
    "                span_start,span_end= self.model(input_ids)\n",
    "                answer = tokens[torch.argmax(span_start):torch.argmax(span_end)+1]\n",
    "                answer = self.bert_convert_tokens_to_string(answer)\n",
    "            elif self.model_type == 'xlnet':\n",
    "                input_vector = {'input_ids': input_ids,\n",
    "                                'start_positions': None,\n",
    "                                'end_positions': None }\n",
    "                outputs = self.model(**input_vector)\n",
    "                answer = tokens[self.to_list(outputs[1])[0][torch.argmax(outputs[0])]:self.to_list(outputs[3])[0][torch.argmax(outputs[2])]+1]\n",
    "                answer = self.xlnet_convert_tokens_to_string(answer)\n",
    "        return answer\n",
    "    \n",
    "    def bert_convert_tokens_to_string(self, tokens):\n",
    "        out_string = ' '.join(tokens).replace(' ##', '').strip()\n",
    "        if '@' in tokens:\n",
    "            out_string = out_string.replace(' ', '')\n",
    "        return out_string\n",
    "\n",
    "    def xlnet_convert_tokens_to_string(self, tokens):\n",
    "        out_string = ''.join(tokens).replace('â–', ' ').strip()\n",
    "        return out_string\n",
    "\n",
    "    def prepare_features(self, question,  passage, max_seq_length = 300, \n",
    "                 zero_pad = False, include_CLS_token = True, include_SEP_token = True):\n",
    "        tokens_a = self.tokenizer.tokenize(question)\n",
    "        tokens_b = self.tokenizer.tokenize(passage)\n",
    "        if len(tokens_a) > max_seq_length - 2:\n",
    "            tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "        tokens = []\n",
    "        if include_CLS_token:\n",
    "            tokens.append(self.tokenizer.cls_token)\n",
    "        for token in tokens_a:\n",
    "            tokens.append(token)\n",
    "        if include_SEP_token:\n",
    "            tokens.append(self.tokenizer.sep_token)\n",
    "        for token in tokens_b:\n",
    "            tokens.append(token)\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        if zero_pad:\n",
    "            while len(input_ids) < max_seq_length:\n",
    "                input_ids.append(0)\n",
    "                input_mask.append(0)\n",
    "        return torch.tensor(input_ids).unsqueeze(0), input_mask, tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "facts = \" My wife is great. \\\n",
    "My project name is e-project. \\\n",
    "My e-mail roberto.dias@gmail.com \\\n",
    "I work for ADP. \\\n",
    "My wife is 33 years old. \\\n",
    "My complete name is Roberto Pereira Silveira. \\\n",
    "I am 40 years old. \\\n",
    "My wife was born in 1985. \\\n",
    "My wife is an urban planner. \\\n",
    "My dog is cool. \\\n",
    "My dog breed is jack russel. \\\n",
    "My dog was born in 2014.\\\n",
    "Best computer science university is Unisinos. \\\n",
    "My favorite city in RS is Sao Leopoldo. \\\n",
    "Best soccer team is Gremio. \\\n",
    "My dog name is Mallu.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased-vocab.txt\r\n",
      "bert-large-cased-whole-word-masking-finetuned-squad-config.json\r\n",
      "bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin\r\n",
      "bert-large-cased-whole-word-masking-finetuned-squad-vocab.txt\r\n",
      "bert-large-uncased-vocab.txt\r\n",
      "bert-large-uncased-whole-word-masking-finetuned-squad-config.json\r\n",
      "bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../../models/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_big = QuestionAnswering(\n",
    "    config_file =   '../../models/bert/bert-large-uncased-whole-word-masking-finetuned-squad-config.json',\n",
    "    weight_file=    '../../models/bert/bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin',\n",
    "    tokenizer_file= '../../models/bert/bert-base-uncased-vocab.txt',\n",
    "    model_type =    'bert'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roberto.dias@gmail.com'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"What is my e-mail?\"   \n",
    "bert_big.get_reply(question, facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mallu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"What is my dog name?\"   \n",
    "bert_big.get_reply(question, facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40 years old'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"What is my age?\"   \n",
    "bert_big.get_reply(question, facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'unisinos'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"What is best CS university?\"   \n",
    "bert_big.get_reply(question, facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sao leopoldo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"What my favorite city?\"   \n",
    "bert_big.get_reply(question, facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gremio'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question =  \"What is best soccer team?\"   \n",
    "bert_big.get_reply(question, facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_new)",
   "language": "python",
   "name": "nlp_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
